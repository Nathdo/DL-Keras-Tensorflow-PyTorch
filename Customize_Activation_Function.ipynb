{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cutomize our activation function using Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape training\n",
      "(48000, 28, 28) (12000, 28, 28) (10000, 28, 28)\n",
      "Shape labels\n",
      "(48000, 10) (12000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Dense, Flatten, Lambda, Input\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras.backend as K\n",
    "import time\n",
    "\n",
    "(train_data, train_label), (test_data, test_label) = mnist.load_data()\n",
    "\n",
    "train_data, valid_data, train_label, valid_label = train_test_split(train_data, train_label, \n",
    "                                                                    test_size = 0.2, random_state = 42 )\n",
    "\n",
    "train_data = train_data / 255.0\n",
    "test_data = test_data / 255.0\n",
    "valid_data = valid_data / 255.0\n",
    "\n",
    "train_label = to_categorical(train_label)\n",
    "test_label = to_categorical(test_label)\n",
    "valid_label = to_categorical(valid_label)\n",
    "\n",
    "print('Shape training')\n",
    "print(train_data.shape, valid_data.shape, test_data.shape)\n",
    "\n",
    "print('Shape labels')\n",
    "print(train_label.shape, valid_label.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.7371 - loss: 1.0182 - val_accuracy: 0.9164 - val_loss: 0.2958\n",
      "Epoch 2/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9213 - loss: 0.2790 - val_accuracy: 0.9360 - val_loss: 0.2279\n",
      "Epoch 3/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9372 - loss: 0.2157 - val_accuracy: 0.9436 - val_loss: 0.1972\n",
      "Epoch 4/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9465 - loss: 0.1803 - val_accuracy: 0.9500 - val_loss: 0.1704\n",
      "Epoch 5/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9567 - loss: 0.1523 - val_accuracy: 0.9548 - val_loss: 0.1514\n",
      "Epoch 6/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9600 - loss: 0.1365 - val_accuracy: 0.9580 - val_loss: 0.1422\n",
      "Epoch 7/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9661 - loss: 0.1173 - val_accuracy: 0.9623 - val_loss: 0.1277\n",
      "Epoch 8/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9680 - loss: 0.1073 - val_accuracy: 0.9632 - val_loss: 0.1223\n",
      "Epoch 9/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9719 - loss: 0.1003 - val_accuracy: 0.9649 - val_loss: 0.1157\n",
      "Epoch 10/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9728 - loss: 0.0914 - val_accuracy: 0.9679 - val_loss: 0.1096\n"
     ]
    }
   ],
   "source": [
    "# Standard Model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape = (28, 28)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 128, activation = 'relu'))\n",
    "model.add(Dense(units = 256, activation = 'relu'))\n",
    "model.add(Dense(units = 10, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer = RMSprop(learning_rate = 0.0001),\n",
    "              loss = CategoricalCrossentropy(),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(train_data, \n",
    "                    train_label, \n",
    "                    epochs = 10, \n",
    "                    validation_data = (valid_data, valid_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7531 - loss: 0.9614 - val_accuracy: 0.9312 - val_loss: 0.2507\n",
      "Epoch 2/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9342 - loss: 0.2320 - val_accuracy: 0.9484 - val_loss: 0.1732\n",
      "Epoch 3/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9558 - loss: 0.1573 - val_accuracy: 0.9577 - val_loss: 0.1445\n",
      "Epoch 4/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9630 - loss: 0.1263 - val_accuracy: 0.9632 - val_loss: 0.1257\n",
      "Epoch 5/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9687 - loss: 0.1083 - val_accuracy: 0.9669 - val_loss: 0.1144\n",
      "Epoch 6/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9739 - loss: 0.0910 - val_accuracy: 0.9688 - val_loss: 0.1038\n",
      "Epoch 7/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9783 - loss: 0.0768 - val_accuracy: 0.9706 - val_loss: 0.0996\n",
      "Epoch 8/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9803 - loss: 0.0682 - val_accuracy: 0.9707 - val_loss: 0.0930\n",
      "Epoch 9/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9832 - loss: 0.0603 - val_accuracy: 0.9720 - val_loss: 0.0902\n",
      "Epoch 10/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9848 - loss: 0.0527 - val_accuracy: 0.9740 - val_loss: 0.0855\n"
     ]
    }
   ],
   "source": [
    "# Model with absolute value of x\n",
    "\n",
    "model_with_lambda = Sequential()\n",
    "model_with_lambda.add(Input(shape = (28, 28)))\n",
    "model_with_lambda.add(Flatten())\n",
    "model_with_lambda.add(Dense(units = 128))\n",
    "model_with_lambda.add(Lambda(lambda x: tf.abs(x)))  # trying with abs \n",
    "model_with_lambda.add(Dense(units = 256))\n",
    "model_with_lambda.add(Lambda(lambda x: tf.abs(x)))\n",
    "model_with_lambda.add(Dense(units = 10, activation = 'softmax'))\n",
    "\n",
    "model_with_lambda.compile(optimizer = RMSprop(learning_rate = 0.0001),\n",
    "              loss = CategoricalCrossentropy(),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history_with_lambda = model_with_lambda.fit(train_data, \n",
    "                                            train_label, \n",
    "                                            epochs = 10, \n",
    "                                            validation_data = (valid_data, valid_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.4608 - loss: 1.7440 - val_accuracy: 0.8759 - val_loss: 0.4680\n",
      "Epoch 2/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.8901 - loss: 0.4095 - val_accuracy: 0.9087 - val_loss: 0.3224\n",
      "Epoch 3/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9099 - loss: 0.3161 - val_accuracy: 0.9204 - val_loss: 0.2775\n",
      "Epoch 4/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9243 - loss: 0.2657 - val_accuracy: 0.9294 - val_loss: 0.2460\n",
      "Epoch 5/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9319 - loss: 0.2380 - val_accuracy: 0.9336 - val_loss: 0.2287\n",
      "Epoch 6/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9364 - loss: 0.2177 - val_accuracy: 0.9408 - val_loss: 0.2083\n",
      "Epoch 7/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9431 - loss: 0.1935 - val_accuracy: 0.9446 - val_loss: 0.1930\n",
      "Epoch 8/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9482 - loss: 0.1825 - val_accuracy: 0.9479 - val_loss: 0.1820\n",
      "Epoch 9/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9532 - loss: 0.1632 - val_accuracy: 0.9511 - val_loss: 0.1718\n",
      "Epoch 10/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9546 - loss: 0.1549 - val_accuracy: 0.9547 - val_loss: 0.1641\n"
     ]
    }
   ],
   "source": [
    "def MyOwnRelu(x):\n",
    "    '''\n",
    "    Function to control our ReLU function\n",
    "    '''\n",
    "    return K.maximum(x, 0.8)\n",
    "\n",
    "\n",
    "model_with_lambda2 = Sequential()\n",
    "model_with_lambda2.add(Input(shape = (28, 28)))\n",
    "model_with_lambda2.add(Flatten())\n",
    "model_with_lambda2.add(Dense(units = 128))\n",
    "model_with_lambda2.add(Lambda(MyOwnRelu))\n",
    "model_with_lambda2.add(Dense(units = 256))\n",
    "model_with_lambda2.add(Lambda(MyOwnRelu))\n",
    "model_with_lambda2.add(Dense(units = 10, activation = 'softmax'))\n",
    "\n",
    "model_with_lambda2.compile(optimizer = RMSprop(learning_rate = 0.0001),\n",
    "              loss = CategoricalCrossentropy(),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history_with_lambda2 = model_with_lambda2.fit(train_data, \n",
    "                                            train_label, \n",
    "                                            epochs = 10, \n",
    "                                            validation_data = (valid_data, valid_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worst results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Github",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
